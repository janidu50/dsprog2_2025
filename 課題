{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5713f683",
   "metadata": {},
   "source": [
    "# Github スクレイピング課題 — Google リポジトリ\n",
    "\n",
    "**目的**：GitHub 上で Google が管理しているリポジトリをスクレイピングして、以下を取得・保存する  \n",
    "- リポジトリ名  \n",
    "- 主要な言語  \n",
    "- スターの数\n",
    "\n",
    "**制約**：GitHub API は使用禁止（スクレイピングで実装）、各リクエストの間に `time.sleep(1)` を入れる。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f888a0",
   "metadata": {},
   "source": [
    "### 必要なライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c82e0262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use existing HEADERS if already defined in another cell (keeps Accept-Language).\n",
    "# Only set a default if HEADERS is not present to avoid overwriting earlier definition.\n",
    "if 'HEADERS' not in globals():\n",
    "    HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "BASE_URL = 'https://github.com/google?tab=repositories'  # Google のリポジトリ一覧\n",
    "DB_PATH = 'google_repos.db'  # 保存する SQLite ファイル名\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f99700",
   "metadata": {},
   "source": [
    "## パーサ関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c427388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_repo_item(item):\n",
    "    \"\"\"\n",
    "    BeautifulSoup の repository リスト要素から\n",
    "    name, language, stars を取り出す。\n",
    "    \"\"\"\n",
    "    # リポジトリ名\n",
    "    name_tag = item.select_one('h3 a')\n",
    "    name = name_tag.get_text(strip=True) if name_tag else None\n",
    "\n",
    "    # メイン言語\n",
    "    lang_tag = item.select_one('[itemprop=\"programmingLanguage\"]')\n",
    "    language = lang_tag.get_text(strip=True) if lang_tag else None\n",
    "\n",
    "    # スター数（テキストを整形）\n",
    "    star_tag = item.select_one('a[href$=\"/stargazers\"]')\n",
    "    stars = None\n",
    "    if star_tag:\n",
    "        stars_text = star_tag.get_text(strip=True)\n",
    "        try:\n",
    "            # '1.2k' -> 1200 のように簡易変換\n",
    "            if 'k' in stars_text.lower():\n",
    "                stars = int(float(stars_text.lower().replace('k','')) * 1000)\n",
    "            else:\n",
    "                stars = int(stars_text.replace(',',''))\n",
    "        except Exception:\n",
    "            stars = stars_text\n",
    "\n",
    "    return name, language, stars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aaed54",
   "metadata": {},
   "source": [
    "## スクレイピング本体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f276189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_google_repos(max_pages=50, sleep_sec=1):\n",
    "    \"\"\"\n",
    "    Google のリポジトリ一覧ページをページングしてスクレイピングする関数。\n",
    "    - max_pages: 最大取得ページ数\n",
    "    - sleep_sec: 各ページ後の待機時間（課題では 1 秒必須）\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        params = {'page': page}\n",
    "        print(f'Fetching page {page} ...')\n",
    "        r = requests.get(BASE_URL, headers=HEADERS, params=params, timeout=15)\n",
    "        if r.status_code != 200:\n",
    "            print('非200レスポンス', r.status_code)\n",
    "            break\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        # GitHub のリポジトリリスト要素を探す（DOMは変わる可能性あり）\n",
    "        repo_list = soup.select('li[itemprop=\"owns\"]')\n",
    "        if not repo_list:\n",
    "            repo_list = soup.select('div#user-repositories-list li')\n",
    "\n",
    "        if not repo_list:\n",
    "            print('リポジトリ要素が見つからなかった。スクレイピング終了。')\n",
    "            break\n",
    "\n",
    "        for item in repo_list:\n",
    "            name, language, stars = parse_repo_item(item)\n",
    "            if name:\n",
    "                results.append({'name': name, 'language': language, 'stars': stars})\n",
    "\n",
    "        time.sleep(sleep_sec)  # 課題条件\n",
    "\n",
    "        # ページング終了判定（Next が無ければ終了）\n",
    "        next_link = soup.select_one('a[rel=\"next\"]')\n",
    "        if not next_link:\n",
    "            print('Next が見つからないため終了')\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "# ネット接続環境で実行する例（コメント解除して実行してください）\n",
    "# repos = scrape_google_repos(max_pages=10, sleep_sec=1)\n",
    "# print('取得件数:', len(repos))\n",
    "# repos[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681193d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22adfd82",
   "metadata": {},
   "source": [
    "## SQLite 保存 & SELECT（Code）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1e157db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_sqlite(records, db_path=DB_PATH):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS google_repos (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT UNIQUE,\n",
    "        language TEXT,\n",
    "        stars INTEGER\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    inserted = 0\n",
    "    for r in records:\n",
    "        try:\n",
    "            cur.execute('INSERT OR IGNORE INTO google_repos (name, language, stars) VALUES (?, ?, ?)',\n",
    "                        (r['name'], r['language'], r['stars']))\n",
    "            if cur.rowcount:\n",
    "                inserted += 1\n",
    "        except Exception as e:\n",
    "            print('Insert error for', r['name'], e)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f'Inserted (or ignored duplicates): {inserted}')\n",
    "\n",
    "def show_data(db_path=DB_PATH, limit=200):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query('SELECT name, language, stars FROM google_repos ORDER BY stars DESC LIMIT ?', conn, params=(limit,))\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# 使用例（スクレイピング実行後）\n",
    "# save_to_sqlite(repos)\n",
    "# df = show_data()\n",
    "# df.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769ff95",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
